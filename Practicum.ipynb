{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __PRACTICUM PROJECT CODE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           \n",
    "           \n",
    "           \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: *Import libraries and configure settings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lZi0PLODk4x"
   },
   "outputs": [],
   "source": [
    "#Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import gspread\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "#Install Machine Learning Packages\n",
    "#!pip install sklearn\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "#Import packages for oversampling and undersampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling._smote.base import Counter\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SN4bvfqZHSVX",
    "outputId": "af334710-c4c2-46ac-d29e-4e97aafa1e6a"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: *Read data and clean*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7EfWWJEEDU5",
    "outputId": "bd3097d9-1bd5-4791-c977-2aa0e1592909"
   },
   "outputs": [],
   "source": [
    "#Read in the change dataset\n",
    "change_df = pd.read_excel('Datasets/Changes_Clean.xlsx')\n",
    "#Read in the incident data set\n",
    "incident_df = pd.read_excel('Datasets/Incidents_Clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display first five rows\n",
    "change_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVLqP1T4Qi2c"
   },
   "outputs": [],
   "source": [
    "#Data Cleaning on Change Dataset\n",
    "\n",
    "##Convert u_total_change_window to int\n",
    "change_df['u_total_change_window'] = change_df['u_total_change_window'].astype(int)\n",
    "\n",
    "##Convert date columns to datetime format. \n",
    "date_cols =['start_date','opened_at','closed_at']\n",
    "for x in date_cols:\n",
    "    change_df[x] = pd.to_datetime(change_df[x])\n",
    "    change_df[x] = change_df[x].fillna(pd.Timestamp(\"20500101 00:00:00\")) #Fill empty dates with dummy date\n",
    "\n",
    "##Fill empty cells with 'Unknown or Not Applicable'\n",
    "##Columns to fill\n",
    "string_cols = ['u_reason_for_emergency','u_applications_impacted.1_map','u_applications_impacted.2_map','u_applications_impacted.3_map','u_applications_impacted.4_map','u_applications_impacted.5_map',\n",
    "               'u_business_map','assignment_group_map','state','risk','u_platform_impacted.1_map','u_platform_impacted.2_map','u_platform_impacted.3_map','u_platform_impacted.4_map','u_platform_impacted.5_map',\n",
    "               'u_application_criticality','u_environment','u_inc_prob_ref','u_validation_status']\n",
    "\n",
    "for x in string_cols:\n",
    "    change_df[x] = change_df[x].fillna(\"Unknown or Not Applicable\")\n",
    "\n",
    "#Add a column for the hour of start of change\n",
    "change_df['hour_start'] = change_df['start_date'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ivywyk5L-LIL"
   },
   "outputs": [],
   "source": [
    "#Data Cleaning on Incidents Dataset\n",
    "\n",
    "##Columns to change\n",
    "inc_date_cols =['resolved_at','opened_at','closed_at']\n",
    "\n",
    "##Convert date columns to datetime format\n",
    "for x in inc_date_cols:\n",
    "    incident_df[x] = pd.to_datetime(incident_df[x])\n",
    "    incident_df[x] = incident_df[x].fillna(pd.Timestamp(\"20500101 00:00:00\")) #Fill empty values with dummy dates\n",
    "    \n",
    "\n",
    "##Fill empty cells with 'Unknown or Not Applicable'\n",
    "##Columns to fill\n",
    "inc_str_cols =['number',\n",
    "'priority',\n",
    "'state',\n",
    "'category',\n",
    "'assignment_group_map',\n",
    "'u_application_map',\n",
    "'u_business_map',\n",
    "'caused_by_change',\n",
    "'impact',\n",
    "'u_platform_map',\n",
    "'root_cause',\n",
    "'u_task_categorization',\n",
    "'urgency',\n",
    "'u_type',\n",
    "'subcategory',\n",
    "'cmdb_ci_map',\n",
    "'close_code',\n",
    "'u_environment',\n",
    "'u_app_criticality',\n",
    "'u_users_affected',\n",
    "'u_service_impact',\n",
    "'u_customer_impact',\n",
    "'u_recovery_complexity',\n",
    "'u_resource_availability',\n",
    "'u_increased_impact_time',\n",
    "'u_expected_time_to_recover']\n",
    "\n",
    "for x in inc_str_cols:\n",
    "    incident_df[x] = incident_df[x].fillna(\"Unknown or Not Applicable\")\n",
    "    \n",
    "##Replace values in the 'u_environment' column of the DataFrame incident_df to standardize names\n",
    "incident_df['u_environment'] = incident_df['u_environment'] \\\n",
    "                               .replace(['Prod','User Acceptance Testing (UAT)'],['Production','UAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdQx3E5tl5ri"
   },
   "outputs": [],
   "source": [
    "#Merge the change with the incident dataset on 'caused_by_change' columm\n",
    "merged_df = change_df.merge(incident_df,how='inner',left_on='number',right_on='caused_by_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "id": "LZQPHz5DuAAJ",
    "outputId": "4c8424af-382f-4624-803f-020a3c09dc7a"
   },
   "outputs": [],
   "source": [
    "#New column to store the hour at which the change was started\n",
    "merged_df['start_hour']  = merged_df['start_date'].dt.hour\n",
    "\n",
    "#Of the changes that caused incidents, what hour of the day were they started?\n",
    "#merged_df.groupby('start_hour')[['start_hour']].agg(['count']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: *Feature engineering*\n",
    "\n",
    "In this section, we create new features for the incident_df dataframe to use in subsequent machine learning models. Eight new columns are created in total. The table below displays the new columns and their purpose.\n",
    "\n",
    "| New Feature | Explanation |\n",
    "| :- | :- |\n",
    "| **risk_rating**   | Tracks riskiness of application based on **changes** |\n",
    "| **app_risk_rating**   | Tracks riskiness of application based on **incidents**  |\n",
    "| **inc_app_counts**   | Calculates the 80th, 90th, 95th, and 97.5th percentiles of the values in app_counts |\n",
    "| **percent_caused_by_change**   | Calculates percentage of incidents in each application that were caused by a change |\n",
    "| **bus_risk_rating**   | Tracks riskiness of application based on the business units affected by change  |\n",
    "| **inc_business_counts**   | Calculates the 80th, 90th, 95th, and 97.5th percentiles of the values in inc_business_counts |\n",
    "| **group_risk_rating**   | Tracks the riskiness of the group that the change is assigned to |\n",
    "| **assignment_counts**  | Calculates the 90th, 90th, 95th, and 97.5th percentiles of the values in assignment_counts |\n",
    "\n",
    "Four columns are created are created by mapping values into categories, ranging from low to high. These represent the riskiness of the application, group, or business unit based on the number of incidents or changes involved. The other columns serve two primary purposes: (a) They aid in bucketing numerical values into the relevant categories, and/or (b) They provide a sense of which applications, groups, or business units might be particularly problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "GXKnAwVmqQKl",
    "outputId": "fc2f6b87-956c-48ac-a6fb-422391fdfd20"
   },
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING\n",
    "\n",
    "\n",
    "#ADD ONE NEW COLUMN (risk_rating) TO incident_df\n",
    "\n",
    "#A dataframe to hold Changes, along with the ICE applications impacted by the change\n",
    "app_df = merged_df[['number_x','u_applications_impacted.1_map','u_applications_impacted.2_map',\n",
    "                    'u_applications_impacted.3_map','u_applications_impacted.4_map',\n",
    "                    'u_applications_impacted.5_map']]\n",
    "#Melt the u_applications_impacted.X_map columns, turning them into rows\n",
    "new_app = pd.melt(app_df, \n",
    "                  id_vars =['number_x'], \n",
    "                  value_vars =['u_applications_impacted.1_map','u_applications_impacted.2_map',\n",
    "                               'u_applications_impacted.3_map','u_applications_impacted.4_map',\n",
    "                               'u_applications_impacted.5_map'])\n",
    "#Drop unneeded duplicate rows\n",
    "new_app = new_app.drop_duplicates()\n",
    "#Create a new column to assign a risk rating to each application.\n",
    "##If the application was affected a certain number of times, rate accordingly\n",
    "app_counts = new_app.groupby('value') \\\n",
    "                .agg(app_counts=('value','count')) \\\n",
    "                .sort_values(by='app_counts',ascending=False) \\\n",
    "                .reset_index()\n",
    "def mapping(value):\n",
    "    if value < 11.4:\n",
    "        return'Low'\n",
    "    elif value >= 11.4 and value < 20:\n",
    "        return 'Medium'\n",
    "    elif value >= 20 and value < 29:\n",
    "        return 'Medium High'\n",
    "    elif value >= 29:\n",
    "        return 'High'\n",
    "app_counts['risk_rating'] = app_counts['app_counts'].map(mapping)\n",
    "#Add the counts and risk rating to the incidents data frame\n",
    "incident_df = incident_df.merge(app_counts,how='left',left_on='u_application_map',right_on='value')\n",
    "#Fill empty values of the risk_rating column\n",
    "incident_df['risk_rating'] = incident_df['risk_rating'].fillna(\"Unknown or Not Applicable\")\n",
    "\n",
    "\n",
    "\n",
    "#ADD TWO NEW COLUMNS (app_risk_rating and inc_app_counts_df) to incident_df\n",
    "\n",
    "#Which applications are associated with the most incidents?\n",
    "inc_app_counts_df = merged_df.groupby('u_application_map') \\\n",
    "                            .agg(inc_app_counts=('u_application_map','count')) \\\n",
    "                            .sort_values(by='inc_app_counts',ascending=False) \\\n",
    "                            .reset_index()\n",
    "#Create a new column to assign a risk rating to each application.\n",
    "##If the application was affected a certain number of times, rate accordingly\n",
    "def inc_app_mapping(value):\n",
    "    if value < 5:\n",
    "        return'Low'\n",
    "    elif value >= 5 and value < 9:\n",
    "        return 'Medium'\n",
    "    elif value >= 9 and value <13:\n",
    "        return 'Medium High'\n",
    "    elif value >= 13:\n",
    "        return 'High'\n",
    "\n",
    "inc_app_counts_df['app_risk_rating'] =  inc_app_counts_df['inc_app_counts'].map(inc_app_mapping)\n",
    "inc_app_counts_df['inc_app_counts'].quantile([.80,.90,.95,.975])\n",
    "incident_df = incident_df.merge(inc_app_counts_df,how='left',left_on='u_application_map',right_on='u_application_map')\n",
    "\n",
    "\n",
    "\n",
    "#ADD ONE NEW COLUMN (inc_percentage) to incident_df.\n",
    "#This column tracks the percent of incidents in each application that were caused by a change\n",
    "all_inc_counts = incident_df.groupby('u_application_map') \\\n",
    "                  .agg(inc_app_counts=('u_application_map','count')) \\\n",
    "                  .sort_values(by='inc_app_counts',ascending=False) \\\n",
    "                  .reset_index()\n",
    "inc_percentage = all_inc_counts.merge(inc_app_counts_df,how='inner', on='u_application_map')\n",
    "inc_percentage['percent_caused_by_change']  = inc_percentage.inc_app_counts_y/inc_percentage.inc_app_counts_x\n",
    "inc_percentage = inc_percentage[(inc_percentage['inc_app_counts_x'] != inc_percentage['inc_app_counts_y']) \n",
    "                                & (inc_percentage['inc_app_counts_x'] > 5)\n",
    "                                & (inc_percentage['inc_app_counts_y'] > 3)]\n",
    "incident_df = incident_df.merge(inc_percentage,how='left',left_on='u_application_map',right_on='u_application_map')\n",
    "\n",
    "\n",
    "\n",
    "#ADD TWO NEW COLUMNS (bus_risk_rating and inc_business_counts) to incident_df\n",
    "#Create a new column to assign risk rating for each business unit\n",
    "inc_business_unit = merged_df.groupby('u_business_map_y') \\\n",
    "                    .agg(inc_business_counts=('u_business_map_y','count')) \\\n",
    "                    .sort_values(by='inc_business_counts',ascending=False) \\\n",
    "                    .reset_index()\n",
    "def bus_unit_mapping(value):\n",
    "    if value < 88:\n",
    "        return'Low'\n",
    "    elif value >= 88 and value < 155:\n",
    "        return 'Medium'\n",
    "    elif value >= 155 and value <184:\n",
    "        return 'Medium High'\n",
    "    elif value >= 247.5:\n",
    "        return 'High'\n",
    "\n",
    "inc_business_unit['bus_risk_rating'] =  inc_business_unit['inc_business_counts'].map(bus_unit_mapping)\n",
    "inc_business_unit['inc_business_counts'].quantile([.80,.90,.95,.975])\n",
    "incident_df = incident_df.merge(inc_business_unit,how='left',left_on='u_business_map',right_on='u_business_map_y')\n",
    "\n",
    "\n",
    "#ADD TWO NEW COLUMNS (assignment_counts and group_risk_rating) to incident_df\n",
    "#Create a new column to assign a risk rating to each application affected by a change\n",
    "assignment_group_df = merged_df.groupby('assignment_group_map_y') \\\n",
    "                        .agg(assignment_counts=('assignment_group_map_y','count')) \\\n",
    "                        .sort_values(by='assignment_counts',ascending=False) \\\n",
    "                        .reset_index()\n",
    "def assign_group_mapping(value):\n",
    "    if value < 191.4:\n",
    "        return'Low'\n",
    "    elif value >= 191.4 and value <288.6 :\n",
    "        return 'Medium'\n",
    "    elif value >= 288.6 and value <375.35 :\n",
    "        return 'Medium High'\n",
    "    elif value >= 375.35:\n",
    "        return 'High'\n",
    "    \n",
    "assignment_group_df['assignment_counts'].quantile([.80,.90,.95,.975])\n",
    "assignment_group_df['group_risk_rating'] =  assignment_group_df['assignment_counts'].map(bus_unit_mapping)\n",
    "incident_df = incident_df.merge(assignment_group_df,how='left',left_on='assignment_group_map',right_on='assignment_group_map_y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show final version of incident_df\n",
    "incident_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4: *Machine learning for Task 1*\n",
    "\n",
    "In this section, we construct and test a machine learning model to classify incidents according to the changes that caused them. This task is divided into two parts: **Task 1a** and **Task 1b**. \n",
    "\n",
    "In **Task 1a**, we define a binary classification model to determine whether or not an incident was caused by a change. Oversampling and undersampling techniques are employed to handle class imbalancing in the dataset. 5-fold cross validation is employed to estimate model accuracy. Several models are tested and compared. (Note to team: We can list these other models here once we decide which to use.) It is found that Random Forest Classifier performs best overall. (Note to team: We can compare the results in a table here.)\n",
    "\n",
    "In **Task 1b**, we construct an algorithm to determine the probability that an incident is caused by a particular change. (Note to team: I will put more detail here this week.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 1a** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flag incidents in the DataFrame that have a valid CMDB configuration item (CI) associated with them \n",
    "#(i.e., \"cmdb_ci_map\" is not \"Unknown or Not Applicable\"). \n",
    "#These incidents will be flagged with a value of 1 in the \"cmdb_flag\" column\n",
    "#Incidents without a valid CI will be flagged with a value of 0.\n",
    "incident_df['cmdb_flag'] = incident_df.cmdb_ci_map.map(lambda x: 0 if x =='Unknown or Not Applicable' else 1)\n",
    "\n",
    "#Take columns for machine learning - part 1\n",
    "inc_ml = incident_df[['root_cause', 'impact','u_business_map','u_task_categorization','app_risk_rating_y',\n",
    "                    'u_customer_impact','u_recovery_complexity','bus_risk_rating',\n",
    "                    'group_risk_rating','percent_caused_by_change','caused_by_change']]\n",
    "\n",
    "#Prepare features for machine learning by handling replacing null values\n",
    "inc_ml['percent_caused_by_change'] = inc_ml['percent_caused_by_change'].fillna(0)\n",
    "inc_ml['group_risk_rating'] = inc_ml['group_risk_rating'].fillna('No risk')\n",
    "inc_ml['bus_risk_rating'] = inc_ml['bus_risk_rating'].fillna('No risk')\n",
    "\n",
    "#Create the response binary response variable\n",
    "inc_ml.loc[:,'response'] = inc_ml.caused_by_change.map(lambda x: 0 if x =='Unknown or Not Applicable' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show dataframe\n",
    "inc_ml.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform oversampling and undersampling to handle class imbalancing in the dataset\n",
    "\n",
    "#Gather predictors (X) and response variable (y)\n",
    "X = inc_ml.iloc[:,0:10]\n",
    "y = inc_ml.iloc[:,-1]\n",
    "\n",
    "#Gather categorical features into list\n",
    "cat_vars = ['root_cause', 'impact','u_business_map','u_task_categorization','app_risk_rating_y',\n",
    "                    'u_customer_impact','u_recovery_complexity','bus_risk_rating','group_risk_rating']\n",
    "\n",
    "#Convert the categorical variables into numerical labels, allowing them to be used as input to machine learning models.\n",
    "label_encoder = LabelEncoder()\n",
    "for i in cat_vars:\n",
    "    X[i] = label_encoder.fit_transform(X[i])\n",
    "\n",
    "#Split data into training and testing data sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,\n",
    "                                               random_state=42, shuffle=True)\n",
    "\n",
    "#Oversampling - Generate synthetic data points to balance the class distribution of a dataset.\n",
    "#The minority class will be increased to 10% of the majority class.\n",
    "over = SMOTENC(sampling_strategy=.1,categorical_features=[0,1,2,3,4,5,6,7,8])\n",
    "\n",
    "#Undersampling - randomly remove some of the majority class samples to further balance the class distribution of the dataset.\n",
    "#The majority class will be reduced to 50% of the minority class.\n",
    "under = RandomUnderSampler(sampling_strategy=.5)\n",
    "\n",
    "#Perform the over and under sampling on training data\n",
    "#Print the number of samples in each class after both oversampling and undersampling have been performed\n",
    "X_train_over, y_train_over = over.fit_resample(X_train, y_train)\n",
    "print(Counter(y_train_over))\n",
    "X_train_under , y_train_under = under.fit_resample(X_train_over, y_train_over)\n",
    "print(Counter(y_train_under))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate initial model accuracy by using 5-Fold Cross-Validation\n",
    "\n",
    "#Create instance of a Random Forest Classifier model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "#Define a machine learning pipeline with three steps: oversampling, undersampling, and model training\n",
    "steps = [('over', over), ('under', under), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "#Perform 5-Fold Cross Validation on the pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=5,  random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "\n",
    "#Calculate mean recall score across all cross-validation scores\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a Random Forest Classifier model on the resampled training dataset\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_under, y_train_under)\n",
    "\n",
    "#Use the trained model to predict the target variable for the test dataset.\n",
    "#Test dataset is subset of the original dataset\n",
    "predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print classification report\n",
    "print(classification_report(y_test,predictions))\n",
    "#Show confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 1b** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge change dataframe with incident dataframe\n",
    "merged_df = change_df.merge(incident_df,how='inner',left_on='number',right_on='caused_by_change')\n",
    "\n",
    "#For splitting merged_df into training and testing datasets\n",
    "def sample_first_prows(data, perc=0.9):\n",
    "    return data.head(int(len(data)*(perc)))\n",
    "\n",
    "#Split merged_df\n",
    "merge_train = sample_first_prows(merged_df)\n",
    "merge_test = merged_df.iloc[max(merge_train.index):]\n",
    "\n",
    "#New column to store the hour at which the change started\n",
    "merged_df['start_hour']  = merged_df['opened_at_y'].dt.hour\n",
    "#Group data frame\n",
    "#merged_df.groupby('start_hour')[['start_hour']].agg(['count'])\n",
    "\n",
    "#New dataframes to take subsets of merged_df and merge_train\n",
    "app_df = merged_df[['number_x','u_applications_impacted.1_map',\n",
    "                    'u_applications_impacted.2_map','u_applications_impacted.3_map',\n",
    "                    'u_applications_impacted.4_map','u_applications_impacted.5_map']]\n",
    "app_df2 = merge_train[['u_application_map','u_applications_impacted.1_map',\n",
    "                       'u_applications_impacted.2_map','u_applications_impacted.3_map',\n",
    "                       'u_applications_impacted.4_map','u_applications_impacted.5_map']]\n",
    "\n",
    "\n",
    "#new_app = pd.melt(app_df, id_vars =['number_x'], value_vars =['u_applications_impacted.1_map','u_applications_impacted.2_map','u_applications_impacted.3_map','u_applications_impacted.4_map','u_applications_impacted.5_map'])\n",
    "#test_app and app_df2 required for dictionaries\n",
    "#Melt the u_applications_impacted columns, turning them into rows\n",
    "test_app = pd.melt(app_df2, \n",
    "                   id_vars =['u_application_map'], \n",
    "                   value_vars =['u_applications_impacted.1_map','u_applications_impacted.2_map',\n",
    "                                'u_applications_impacted.3_map','u_applications_impacted.4_map',\n",
    "                                'u_applications_impacted.5_map'])\n",
    "\n",
    "#Similar steps for platform dictionary\n",
    "plat_df = merged_df[['u_platform_map','u_platform_impacted.1_map',\n",
    "                     'u_platform_impacted.2_map','u_platform_impacted.3_map',\n",
    "                     'u_platform_impacted.4_map','u_platform_impacted.5_map']]\n",
    "plat_df = pd.melt(plat_df, \n",
    "                  id_vars = ['u_platform_map'], \n",
    "                  value_vars=['u_platform_impacted.1_map','u_platform_impacted.2_map',\n",
    "                              'u_platform_impacted.3_map','u_platform_impacted.4_map',\n",
    "                              'u_platform_impacted.5_map'])\n",
    "plat_df = plat_df.drop_duplicates()\n",
    "plat_df = plat_df[(plat_df['value'] != 'Unknown or Not Applicable') \n",
    "                  & (plat_df['u_platform_map'] != 'Unknown or Not Applicable') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionaries to store weights\n",
    "\n",
    "#Dictionary 1 -- Application Dictionary to Map Applications\n",
    "test_app = test_app.drop_duplicates()\n",
    "test_app = test_app[test_app['value'] != 'Unknown or Not Applicable']\n",
    "d = defaultdict(set)\n",
    "for counter, x in enumerate(test_app.u_application_map):\n",
    "    y = test_app.iloc[counter,2]\n",
    "    if x not in d.keys():\n",
    "        d[x].add(y)\n",
    "    if y not in d[x]:\n",
    "        d[x].add(y)\n",
    "\n",
    "#Dictionary 2 -- Platform Dictionary to Map Platforms\n",
    "plat_dict = defaultdict(set)\n",
    "for counter, x in enumerate(plat_df.u_platform_map):\n",
    "    y = plat_df.iloc[counter,2]\n",
    "    if x not in plat_dict.keys():\n",
    "        plat_dict[x].add(y)\n",
    "    if y not in d[x]:\n",
    "        plat_dict[x].add(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define variable to store merged dataframe\n",
    "df = merged_df\n",
    "#Define empty list to store \"hits\"\n",
    "hits = []\n",
    "#Define empty list to store dataframe lengths\n",
    "df_lens= [] \n",
    "\n",
    "#Take subset of columns to use in identifying possible changes\n",
    "test_inc = df[['opened_at_y','u_application_map','u_business_map_y','u_platform_map','caused_by_change']]\n",
    "\n",
    "#Convert dataframe to list of flat lists\n",
    "#Loop over each row of merged dataframe \n",
    "for x in range(len(df)):\n",
    "    #Select single row at each iteration and store in test_inc2\n",
    "    test_inc2 = test_inc[x:x+1]\n",
    "    flat_list = []\n",
    "    #Convert values of dataframe to list\n",
    "    test_list = test_inc2.values.tolist()\n",
    "    #Flatten list and store in flat_list\n",
    "    for sublist in test_list:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "\n",
    "#Look for change 2 days before incident and 3 days after\n",
    "refined_df = df[((df['closed_at_x']>=flat_list[0] - timedelta(days=3)) \n",
    "                      & (df['closed_at_x']<=flat_list[0] + timedelta(days=2)))] \n",
    "\n",
    "#Take subset of refined_df\n",
    "refined_df = refined_df[['u_applications_impacted.1_map','u_applications_impacted.2_map',\n",
    "                         'u_applications_impacted.3_map','u_applications_impacted.4_map',\n",
    "                         'u_applications_impacted.5_map', 'u_platform_impacted.1_map',\n",
    "                         'u_platform_impacted.2_map','u_platform_impacted.3_map',\n",
    "                         'u_platform_impacted.4_map','u_platform_impacted.5_map',\n",
    "                         'u_business_map_x', 'opened_at_y','caused_by_change']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a weight and a flag column for each column of refined_df\n",
    "#These will store the weights for each category and whether or not it was flagged\n",
    "for x in range(11):\n",
    "    refined_df['weight' + str(x + 1)] = .10\n",
    "    refined_df['flag' + str(x+1) ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See first five rows of refined_df\n",
    "refined_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the ICE applications impacted by the change\n",
    "app_columns = ['u_applications_impacted.1_map','u_applications_impacted.2_map',\n",
    "               'u_applications_impacted.3_map',\t'u_applications_impacted.4_map',\n",
    "               'u_applications_impacted.5_map']\n",
    "\n",
    "#The index of the first weight column for the category that corresponds to applications impacted\n",
    "col_index = 14\n",
    "\n",
    "#Update weight columns for appropriate category if not unknown or inapplicable\n",
    "if flat_list[1] != 'Unknown or Not Applicable':\n",
    "    for x in app_columns:\n",
    "        #Check whether the application impacted is present in a dictionary called d\n",
    "        if flat_list[1] not in d.keys():\n",
    "            break\n",
    "        #Check whether the value in the current column (x) is present in the list of impacted applications (d[flat_list[1]])\n",
    "        for count, y in enumerate(refined_df[x]):\n",
    "            #If present, set the corresponding weight column for the category to 1.\n",
    "            if  y in d[flat_list[1]]:\n",
    "                refined_df.iloc[count,col_index] =1\n",
    "            if count == len(refined_df) -1:\n",
    "                col_index = col_index + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the ICE platforms impacted by the change\n",
    "plat_columns = ['u_platform_impacted.1_map', 'u_platform_impacted.2_map',\n",
    "                'u_platform_impacted.3_map','u_platform_impacted.4_map',\n",
    "                'u_platform_impacted.5_map']\n",
    "\n",
    "#The index of the first weight column for the category that corresponds to platforms impacted\n",
    "col_index = 24\n",
    "\n",
    "#Update weight columns for appropriate category if not unknown or inapplicable\n",
    "if flat_list[3] != 'Unknown or Not Applicable':\n",
    "    for x in plat_columns:\n",
    "        if flat_list[3] not in d.keys():\n",
    "            break\n",
    "        for count, y in enumerate(refined_df[x]):\n",
    "            if  y in d[flat_list[3]]: #Should this be plat_dict?\n",
    "                refined_df.iloc[count,col_index] =1\n",
    "            if count == len(refined_df) -1:\n",
    "                col_index = col_index + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update weight columns for impacted businesses\n",
    "\n",
    "#If third element is unknown or not applicable, then set the variable col_index to 34\n",
    "if flat_list[2] != 'Unknown or Not Applicable':\n",
    "    col_index =34\n",
    "    #Iterate over the values in the 'u_business_map_x' column of the DataFrame refined_df\n",
    "    for count, x in enumerate(refined_df.u_business_map_x):\n",
    "        #Check whether each value is equal to third element in flat_list\n",
    "        if x == flat_list[2]:\n",
    "            #Sets the value of the corresponding row and column in refined_df to 1.\n",
    "            refined_df.iloc[count,col_index] =1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather weights and flags in new dataframes\n",
    "weights = refined_df[['weight1','weight2','weight3','weight4',\n",
    "                      'weight5','weight6','weight7','weight8',\n",
    "                      'weight9','weight10','weight11']]\n",
    "flags = refined_df[['flag1','flag2','flag3','flag4',\n",
    "                    'flag5','flag6','flag7','flag8',\n",
    "                    'flag9','flag10','flag11']]\n",
    "\n",
    "#Convert to numpy array\n",
    "np_weights = weights.to_numpy()\n",
    "#print(np_weights)\n",
    "np_flag = flags.to_numpy()\n",
    "#print(np_flag)\n",
    "\n",
    "#Calculate probabilities based on weights and flag\n",
    "prob_score = np.sum(np_weights*np_flag,axis=1)\n",
    "\n",
    "#Store probability scores in a new column\n",
    "refined_df['probability'] = prob_score\n",
    "\n",
    "#Rank each probability score\n",
    "refined_df['rank'] = refined_df['probability'].rank(ascending=False)\n",
    "\n",
    "#Show top five\n",
    "refined_df = refined_df[refined_df['rank']<=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record if any hits\n",
    "if flat_list[4] in refined_df['caused_by_change'].values:\n",
    "    hits.append(1)\n",
    "else:\n",
    "    hits.append(0) \n",
    "\n",
    "#Append length of refined_df\n",
    "df_lens.append(len(refined_df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lens\n",
    "sum(hits)\n",
    "refined_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 5: *Machine Learning for Task 2*\n",
    "\n",
    "# UNDER CONSTRUCTION #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "fNC7r36cWeom",
    "outputId": "434e665b-11d3-46c8-c8c0-cbc996200450"
   },
   "outputs": [],
   "source": [
    "#Set binary response variable\n",
    "inc_ml.loc[:,'response'] = inc_ml.caused_by_change.map(lambda x: 0 if x =='Unknown or Not Applicable' else 1)\n",
    "\n",
    "inc_ml.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wiSel_ZLgoSr",
    "outputId": "63de215c-c29c-43c6-a9c8-d64a729b387e"
   },
   "outputs": [],
   "source": [
    "#Perform oversampling to handle class imbalancing in the dataset\n",
    "X = inc_ml.iloc[:,0:12]\n",
    "y = inc_ml.iloc[:,-1]\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for i in X.columns:\n",
    "  X[i] = label_encoder.fit_transform(X[i])\n",
    "\n",
    "\n",
    "print(Counter(y))\n",
    "X = X.values\n",
    "y = y.values\n",
    "X, y = smote.fit_resample(X,y)\n",
    "\n",
    "print(Counter(y))\n",
    "\n",
    "chi2_selector = SelectKBest(chi2, k= 'all')\n",
    "X_kbest = chi2_selector.fit_transform(X, y)\n",
    "\n",
    "X = X_kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-PRRjmYigjb8",
    "outputId": "46ddb11a-d3e7-427e-ed4b-c81f0b1a5dbf"
   },
   "outputs": [],
   "source": [
    "#Define classifiers\n",
    "log_reg_model = LogisticRegression(random_state = 42)\n",
    "decision_tree_model = DecisionTreeClassifier(criterion=\"entropy\",\n",
    "                                     random_state=0)\n",
    "knn = KNeighborsClassifier()\n",
    "rfc = RandomForestClassifier(random_state = 42)\n",
    "#accuracies = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "cross_validation(rfc,X,y)\n",
    "#log_result = cross_validation(log_reg_model, X, y, 5)\n",
    "#print(log_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIfPKQF8mpYs"
   },
   "outputs": [],
   "source": [
    "#Split data into training and testing data sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,\n",
    "                                               random_state=42, shuffle=True)\n",
    "#decision_tree_model.fit(X_train,y_train)\n",
    "#y_pred = decision_tree_model.predict(X_test)\n",
    "\n",
    "#decision_tree_model.score(X_test,y_test)\n",
    "\n",
    "#sc = StandardScaler()\n",
    "#X_train = sc.fit_transform(X_train)\n",
    "#X_test = sc.fit_transform(X_test)\n",
    "\n",
    "\n",
    "#log_reg_model.fit(X_train,y_train)\n",
    "#lg_pred = log_reg_model.predict(X_test)\n",
    "#log_reg_model.score(X_test, y_test)\n",
    "\n",
    "#knn.fit(X_train,y_train)\n",
    "#y_pred = knn.predict(X_test)\n",
    "#knn.score(X_test,y_test)\n",
    "\n",
    "#Fit random forest on training data\n",
    "rfc.fit(X_train,y_train)\n",
    "#Make predictions on testing data\n",
    "y_pred = rfc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJQtU_aEoPAC"
   },
   "outputs": [],
   "source": [
    "#Visually compare the actual results and the predicted results\n",
    "data = {\"y_true\":y_test,\"y_prediction\":y_pred}\n",
    "\n",
    "test = pd.DataFrame(data)\n",
    "\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SANDBOX BELOW - WILL NOT BE INCLUDED IN FINAL #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "HSvtsP3qqq0l",
    "outputId": "663d2705-10fb-4f2d-bb48-5a89f9f8bb7e"
   },
   "outputs": [],
   "source": [
    "#Use a Confusion Matrix to display the results\n",
    "ConfusionMatrixDisplay.from_predictions(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 774
    },
    "id": "0GYNARrQZOGB",
    "outputId": "ded7db4c-1082-4556-9366-fe544d1a5bb7"
   },
   "outputs": [],
   "source": [
    "#time_diff_df = merged_df[['closed_at_x','opened_at_y']]\n",
    "#time_diff_df['time_diff'] = time_diff_df.closed_at_x - time_diff_df.opened_at_y\n",
    "\n",
    "test_df = merged_df[:10]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4O0YrtKyfGaB"
   },
   "outputs": [],
   "source": [
    "test_inc = test_df[['opened_at_y','u_application_map','u_business_map_y']]\n",
    "test_inc = test_inc[5:6]\n",
    "test_list = test_inc.values.tolist()\n",
    "flat_list = []\n",
    "for sublist in test_list:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "\n",
    "refined_df = test_df[((test_df['closed_at_x']>=flat_list[0] - timedelta(days=60)) & (test_df['closed_at_x']<=flat_list[0] + timedelta(days=2)))]\n",
    "\n",
    "refined_df = refined_df[['u_applications_impacted.1_map','u_applications_impacted.2_map','u_applications_impacted.3_map','u_applications_impacted.4_map','u_applications_impacted.5_map', 'u_business_map_x', 'opened_at_y','caused_by_change']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VT6rZMZkkh-u"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "insert = 1\n",
    "for x in range(6):\n",
    "    if x>0:\n",
    "        insert +=2\n",
    "    refined_df.insert(insert,'app_weight' + str(x+1),.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TcDLWHaEwUxi",
    "outputId": "728e87b6-adbc-4719-a587-b756a65bfae2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np1 = np.array([[.15,.15,.15,.15,.15,.15],[.15,.15,.15,.15,.15,.15]])\n",
    "\n",
    "np2 = np.array([[0,1,0,0,1,0],[0,1,0,0,1,0]])\n",
    "\n",
    "np.sum(np1 * np2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "bng7xJ8dwcPu",
    "outputId": "993d004d-bcaa-4e93-9ec6-0d50d9db366b"
   },
   "outputs": [],
   "source": [
    "refined_df.insert(17, 'app6_flag',refined_df['u_applications_impacted.1_map'].map(lambda x: 1 if x == flat_list[1] else 0))\n",
    "refined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CSlAndi7BwX"
   },
   "outputs": [],
   "source": [
    "weights = refined_df[['app_weight1','app_weight2','app_weight3','app_weight4','app_weight5']]\n",
    "\n",
    "flags = refined_df[['app1_flag','app2_flag','app3_flag','app4_flag','app5_flag']]\n",
    "\n",
    "np_weights = weights.to_numpy()\n",
    "\n",
    "np_flag = flags.to_numpy()\n",
    "\n",
    "np.sum(np_weights*np_flag,axis=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
